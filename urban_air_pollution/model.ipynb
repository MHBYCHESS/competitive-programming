{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Air Pollution Challenge:\n",
    "\n",
    "The objective of this challenge is to predict PM2.5 particulate matter concentration in the air every day for each city. PM2.5 refers to atmospheric particulate matter that have a diameter of less than 2.5 micrometers and is one of the most harmful air pollutants. PM2.5 is a common measure of air quality that normally requires ground-based sensors to measure. The data covers the last three months, spanning hundreds of cities across the globe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shap\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility error function\n",
    "def rmse(y,x):\n",
    "    return np.sqrt(mean_squared_error(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('./raw_data/Train.csv')\n",
    "test = pd.read_csv('./raw_data/Test.csv')\n",
    "sub = pd.read_csv('./raw_data/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"Checks a given dataframe for missing values and\n",
    "  types of the data features.\n",
    "  \"\"\"\n",
    "  total = data.isna().sum()\n",
    "  percent = (data.isna().sum()/data.isna().count()*100)\n",
    "  tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "  types = []\n",
    "  for col in data.columns:\n",
    "      dtype = str(data[col].dtype)\n",
    "      types.append(dtype)\n",
    "  tt['Types'] = types\n",
    "  return(np.transpose(tt))\n",
    "\n",
    "check_missing_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75% of target observations in the train set fall within 80.\n",
    "# This means that there exist outliers since the max value of the target feature\n",
    "# is 815 as seen from train.describe().\n",
    "print(f'with outliers: {len(train_df)}')\n",
    "train = train_df[train_df['target'] <= 500]\n",
    "print(f'Without outliers: {len(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping target related features in the train set\n",
    "drop_cols = ['target_min', 'target_max', 'target_variance', 'target_count']\n",
    "\n",
    "train.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train['Place_ID'] = encoder.fit_transform(train.Place_ID).astype('int32')\n",
    "test['Place_ID'] = encoder.fit_transform(test.Place_ID).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day'] = pd.to_datetime(train['Date']).dt.day.astype('int32')\n",
    "train['month'] = pd.to_datetime(train['Date']).dt.month.astype('int32')\n",
    "\n",
    "test['day'] = pd.to_datetime(test['Date']).dt.day.astype('int32')\n",
    "test['month'] = pd.to_datetime(test['Date']).dt.month.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "corr = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barhistogram of correlations to the target variable\n",
    "(corr\n",
    "     .target\n",
    "     .drop(\"target\") # can't compare the variable under study to itself\n",
    "     .sort_values(ascending=False)\n",
    "     .plot\n",
    "     .barh(figsize=(9,6)))\n",
    "plt.title(\"correlation bar_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['target', 'Date', 'Place_ID X Date', 'Place_ID', 'L3_AER_AI_sensor_altitude']\n",
    "\n",
    "y = train['target']\n",
    "X = train.drop(drop, axis=1)\n",
    "\n",
    "ids = test['Place_ID X Date']\n",
    "test = test.drop(drop[1:], axis=1)\n",
    "\n",
    "X = X.fillna(value=X.median()).astype('float32')\n",
    "test = test.fillna(value=test.median()).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM model\n",
    "lgb_params = {\n",
    "    'metric' : 'rmse',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.025, #0.025 (32.3533)\n",
    "    'max_depth': 11, \n",
    "    'num_leaves': 80,\n",
    "    'objective': 'regression',\n",
    "    #'subsample': 0.9,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    #'lambda_l2': 0.2,\n",
    "    'max_bin': 1000 }\n",
    "\n",
    "# split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#train_data = lgbm.Dataset(X_train, label=y_train)\n",
    "#test_data = lgbm.Dataset(X_val, label=y_val)\n",
    "\n",
    "#lgb_model = lgbm.train(lgb_params, train_data, valid_sets=[train_data, test_data],\n",
    "#                       num_boost_round=9000, early_stopping_rounds=100\n",
    "#                      ) #0.03lr\n",
    "\n",
    "#lgb_df = lgbm.Dataset(X, y)\n",
    "#lgb_model = lgbm.train(lgb_params, lgb_df, num_boost_round=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM with 8-fold CV\n",
    "folds = KFold(n_splits=8, shuffle=False, random_state=42)\n",
    "\n",
    "scores = []\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    trn_x, trn_y = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    tr_data = lgbm.Dataset(trn_x, label=trn_y)\n",
    "    val_data = lgbm.Dataset(val_x, label=val_y)\n",
    "\n",
    "    lgb_model = lgbm.train(lgb_params, tr_data, valid_sets=[tr_data, val_data],\n",
    "                           num_boost_round=5000, early_stopping_rounds=100\n",
    "                          ) \n",
    "    root_mse = rmse(val_y, lgb_model.predict(val_x))\n",
    "    scores.append(root_mse)\n",
    "    print(root_mse)\n",
    "\n",
    "print(\"Average score in 5-fold CV:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(lgb_model.feature_importance(),\n",
    "                                   index = trn_x.columns,\n",
    "                                   columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time shap_values = shap.TreeExplainer(lgb_model).shap_values(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shap summary plot above shows the 30 most important features.\n",
    "For each feature a distribution is plotted on how the train samples influence the model outcome. \n",
    "The more red the dots, the higher the feature value, the more blue the lower the feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making predictions\n",
    "predictions = lgb_model.predict(test, num_iteration=lgb_model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Place_ID X Date'] = ids\n",
    "sub['target'] = predictions\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_score = lgb_model.best_score['valid_1']['rmse']\n",
    "lgbm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir ./submissions\n",
    "sub.to_csv(f'./submissions/sub_lgb{np.round(lgbm_score, 4)}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
